# Cross-lingual Language Model Pretraining
Author: Alexis Conneau, Guillaume Lample

Category: Unsupervised

Conference: arXiv

Link: https://arxiv.org/abs/1901.07291

Status: Pending

Topic: NMT, Text , Transformers

Year: 2019

# Questions

### What did authors try to accomplish?

### What were the key elements of the approach?

### What can you use yourself from this paper?

### What other references to follow?

---