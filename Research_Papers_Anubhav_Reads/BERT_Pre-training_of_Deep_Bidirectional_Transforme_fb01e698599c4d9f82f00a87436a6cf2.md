# BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding

Author: Jacob Devlin, Ming-Wei Chang
Conference: arXiv
Date Added: Sep 15, 2020 7:16 PM
Hot: ðŸ”¥
Link: https://arxiv.org/abs/1810.04805
Source: https://www.notion.so/AI-Papers-to-Read-in-2020-5977476ed8cd43859f050a8aed418b98
Status: Pending
Topic: Text , Transformers
Year: 2018

# Questions

### What did authors try to accomplish?

### What were the key elements of the approach?

### What can you use yourself from this paper?

### What other references to follow?

---